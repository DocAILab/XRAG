# from llama_index.embeddings.huggingface import HuggingFaceEmbedding
# # from llama_index.legacy.embeddings import HuggingFaceEmbedding

# def get_embedding(name,embed_batch_size=16):
#     return HuggingFaceEmbedding(
#         model_name=name,
#         embed_batch_size=embed_batch_size,
#         # cache_folder="./embedding_model"
#     )


from langchain.embeddings.huggingface import HuggingFaceEmbeddings
model_kwargs = {
    "device": "cuda",
    "trust_remote_code": True
} 
def get_embedding(name, embed_batch_size=16):
    encode_kwargs = {"batch_size": embed_batch_size, 'device': 'cuda'}
    embeddings = HuggingFaceEmbeddings(
        model_name=name,
        encode_kwargs=encode_kwargs,
        model_kwargs=model_kwargs,
        # embed_batch_size=128,
    )
    return embeddings
