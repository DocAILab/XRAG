[api_keys]
api_key = "sk-xxxx"
api_base = "https://api.openai.com/v1"
api_name = "gpt-4o"
auth_token = "hf_xxx"


[logging]
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_level = "INFO"
# Path to log file - comment or set to empty string to disable file logging
log_file = "logs/xrag.log"
# Log format
log_format = "[%(asctime)s,%(msecs)03d] %(levelname)-8s - (%(name)s) %(filename)s, ln %(lineno)d: %(message)s"


[settings]
llm = "openai" # openai, huggingface, ollama
ollama_model = "llama2:7b" # ollama model name
huggingface_model = "llama" # huggingface model name
embeddings = "BAAI/bge-large-en-v1.5"
split_type = "sentence"
chunk_size = 128
window_size = 3 # when split_type is sentence_window
dataset = "hotpot_qa"
dataset_download_timeout = 300 # seconds
# dataset_path = "data/xxx.json" # If dataset is custom, set the path to the custom dataset
persist_dir = "storage"
llamaIndexEvaluateModel = "Qwen/Qwen1.5-7B-Chat-GPTQ-Int8"
deepEvalEvaluateModel = "Qwen/Qwen1.5-7B-Chat-GPTQ-Int8"
upTrainEvaluateModel = "qwen:7b-chat-v1.5-q8_0"
evaluateApiName = ""
evaluateApiKey = ""
evaluateApiBase = ""
output = ""
n = 100
test_init_total_number_documents = 20
extra_number_documents = 20
extra_rate_documents = 0.1
test_all_number_documents = 40
experiment_1 = false
retriever = "BM25"
retriever_mode = 0
postprocess_rerank = "long_context_reorder"
query_transform = "none"
metrics = ["NLG_chrf", "NLG_meteor", "NLG_wer", "NLG_cer", "NLG_chrf_pp","NLG_perplexity", "NLG_rouge_rouge1", "NLG_rouge_rouge2", "NLG_rouge_rougeL", "NLG_rouge_rougeLsum"]


[seper]
# SePer (Semantic Perplexity) metric configuration
enabled = false
generation_model = "meta-llama/Llama-2-7b-chat-hf"
entailment_model = "microsoft/deberta-v2-xlarge-mnli"
device = "cuda"
num_generations = 10
temperature = 1.0
max_new_tokens = 128
computation_chunk_size = 8
prompt_type = "default"
max_context_words = 512
use_soft_clustering = true


[prompt]
text_qa_template_path = "src/xrag/prompts/text_qa_template.txt"
refine_template_path = "src/xrag/prompts/refine_template.txt"


[self_rag]
enabled = false # when enabled, ignore other config sections and use self-rag
model_name = "selfrag/selfrag_llama2_7b"
retriever_model = "facebook/contriever-msmarco"
download_dir = ""
dtype = "half"
temperature = 0.0
top_p = 1.0
max_tokens = 100
skip_special_tokens = false


[adaptive_rag]
enabled = false # when enabled, ignore other config sections and use adaptive-rag
